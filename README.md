# WebASRCore

WebASRCore æ˜¯ä¸€å¥—ç„¡ç‹€æ…‹çš„ TypeScript æœå‹™é›†åˆï¼Œå°ˆç‚ºç€è¦½å™¨ç«¯èªéŸ³è™•ç†è¨­è¨ˆã€‚æä¾›èªéŸ³æ´»å‹•æª¢æ¸¬ï¼ˆVADï¼‰ã€å–šé†’è©æª¢æ¸¬å’ŒèªéŸ³è­˜åˆ¥ï¼ˆWhisperï¼‰çš„ç´”å‡½æ•¸å¯¦ç¾ï¼Œå®Œå…¨åœ¨ç€è¦½å™¨ä¸­é‹è¡Œã€‚

## åŠŸèƒ½ç‰¹è‰²

- **ğŸ¯ ç„¡ç‹€æ…‹è¨­è¨ˆ**ï¼šæ‰€æœ‰æœå‹™éƒ½æ˜¯ç´”å‡½æ•¸ï¼Œæ²’æœ‰å…§éƒ¨ç‹€æ…‹
- **ğŸ¤ VADï¼ˆèªéŸ³æ´»å‹•æª¢æ¸¬ï¼‰**ï¼šä½¿ç”¨ Silero VAD æ¨¡å‹
- **ğŸ”Š å–šé†’è©æª¢æ¸¬**ï¼šOpenWakeWord æ¨¡å‹ï¼ˆHey Jarvisã€Hey Mycroftã€Alexaï¼‰
- **âœï¸ èªéŸ³è­˜åˆ¥**ï¼šé€é transformers.js ä½¿ç”¨ Whisper æ¨¡å‹
- **ğŸš€ ç€è¦½å™¨å„ªå…ˆ**ï¼šä½¿ç”¨ WebAssembly å®Œå…¨åœ¨ç€è¦½å™¨ä¸­é‹è¡Œ
- **ğŸ“¦ TypeScript**ï¼šå®Œæ•´çš„å‹åˆ¥å®šç¾©ï¼Œæä¾›æ›´å¥½çš„é–‹ç™¼é«”é©—
- **ğŸ”§ é…ç½®ç®¡ç†**ï¼šé›†ä¸­å¼é…ç½®ç®¡ç†å™¨ï¼Œæ”¯æ´æ‰€æœ‰åƒæ•¸è‡ªè¨‚

## å®‰è£

```bash
npm install web-asr-core
```

## å¿«é€Ÿé–‹å§‹

```typescript
import {
  // è¨»å†Šè¡¨å‡½æ•¸
  loadRegistry,
  resolveVad,
  resolveWakeword,
  resolveWhisper,
  
  // VAD å‡½æ•¸
  loadVadSession,
  createVadState,
  processVad,
  
  // å–šé†’è©å‡½æ•¸
  loadWakewordResources,
  createWakewordState,
  processWakewordChunk,
  
  // Whisper å‡½æ•¸
  loadWhisperResources,
  transcribe,
  
  // é…ç½®ç®¡ç†
  ConfigManager,
  
  // å‹åˆ¥
  DEFAULT_VAD_PARAMS,
  DEFAULT_WAKEWORD_PARAMS,
} from 'web-asr-core';

// è¼‰å…¥æ¨¡å‹è¨»å†Šè¡¨
const registry = await loadRegistry('./models/global_registry.json');

// åˆå§‹åŒ–æœå‹™...
```

## ä½¿ç”¨ç¯„ä¾‹

### VADï¼ˆèªéŸ³æ´»å‹•æª¢æ¸¬ï¼‰

```typescript
// 1. è¼‰å…¥ VAD æ¨¡å‹
const vadInfo = resolveVad(registry);
const vadSession = await loadVadSession(vadInfo.modelUrl);

// 2. å»ºç«‹åˆå§‹ç‹€æ…‹
let vadState = createVadState();

// 3. è™•ç†éŸ³è¨Šå¡Šï¼ˆ16kHzï¼ŒFloat32Arrayï¼‰
const audioChunk = new Float32Array(512); // 32ms at 16kHz
const vadResult = await processVad(
  vadSession,
  vadState,
  audioChunk,
  DEFAULT_VAD_PARAMS
);

// 4. æ›´æ–°ç‹€æ…‹ä»¥ä¾›ä¸‹æ¬¡è¿­ä»£
vadState = vadResult.state;

// 5. æª¢æŸ¥æ˜¯å¦æª¢æ¸¬åˆ°èªéŸ³
if (vadResult.detected) {
  console.log('æª¢æ¸¬åˆ°èªéŸ³ï¼', vadResult.score);
}
```

### å–šé†’è©æª¢æ¸¬

```typescript
// 1. è¼‰å…¥å–šé†’è©æ¨¡å‹ï¼ˆä½¿ç”¨æ–°çš„ APIï¼‰
const config = new ConfigManager();
const wwResources = await loadWakewordResources('hey_jarvis', config);

// 2. å»ºç«‹åˆå§‹ç‹€æ…‹
let wwState = createWakewordState(wwResources.dims);

// 3. è™•ç†éŸ³è¨Šå¡Šï¼ˆ16kHzï¼ŒFloat32Arrayï¼‰
const audioChunk = new Float32Array(1280); // 80ms at 16kHz
const wwResult = await processWakewordChunk(
  wwResources,
  wwState,
  audioChunk,
  { threshold: config.wakeword.hey_jarvis.threshold }
);

// 4. æ›´æ–°ç‹€æ…‹ä»¥ä¾›ä¸‹æ¬¡è¿­ä»£
wwState = wwResult.state;

// 5. æª¢æŸ¥æ˜¯å¦æª¢æ¸¬åˆ°å–šé†’è©
if (wwResult.triggered) {
  console.log('æª¢æ¸¬åˆ°å–šé†’è©ï¼', wwResult.score);
  // æª¢æ¸¬å¾Œé‡è¨­ç‹€æ…‹
  wwState = resetWakewordState(wwResources.dims);
}
```

### Whisper èªéŸ³è­˜åˆ¥

```typescript
// 1. è¼‰å…¥ Whisper æ¨¡å‹
const whisperInfo = resolveWhisper(registry, 'whisper-base');
const whisperResources = await loadWhisperResources(
  whisperInfo.path,
  { quantized: whisperInfo.quantized }
);

// 2. è½‰éŒ„éŸ³è¨Šï¼ˆ16kHzï¼ŒFloat32Arrayï¼‰
const audioData = new Float32Array(16000 * 5); // 5 ç§’éŸ³è¨Š
const result = await transcribe(
  whisperResources,
  audioData,
  {
    language: 'zh',  // æ”¯æ´ä¸­æ–‡
    task: 'transcribe',
    returnSegments: true,
  }
);

console.log('è½‰éŒ„çµæœï¼š', result.text);
if (result.segments) {
  result.segments.forEach(segment => {
    console.log(`[${segment.start}-${segment.end}]: ${segment.text}`);
  });
}
```

## å®Œæ•´ç¯„ä¾‹ï¼šèªéŸ³åŠ©æ‰‹

```typescript
import * as WebASRCore from 'web-asr-core';

async function createVoiceAssistant() {
  // è¼‰å…¥è¨»å†Šè¡¨å’Œæ¨¡å‹
  const registry = await WebASRCore.loadRegistry('./models/global_registry.json');
  const config = new WebASRCore.ConfigManager();
  
  // åˆå§‹åŒ– VAD
  const vadInfo = WebASRCore.resolveVad(registry);
  const vadSession = await WebASRCore.loadVadSession(vadInfo.modelUrl);
  let vadState = WebASRCore.createVadState();
  
  // åˆå§‹åŒ–å–šé†’è©
  const wwResources = await WebASRCore.loadWakewordResources('hey_jarvis', config);
  let wwState = WebASRCore.createWakewordState(wwResources.dims);
  
  // åˆå§‹åŒ– Whisper
  const whisperInfo = WebASRCore.resolveWhisper(registry, 'whisper-base');
  const whisperResources = await WebASRCore.loadWhisperResources(
    whisperInfo.path,
    { quantized: true }
  );
  
  // éŸ³è¨Šæ”¶é›†ç·©è¡å€
  const audioBuffer: Float32Array[] = [];
  let isListening = false;
  
  // è™•ç†éŸ³è¨Šæµï¼ˆæ¯ 80ms è™•ç†æ–°çš„éŸ³è¨Šå¡Šï¼‰
  async function processAudioChunk(chunk: Float32Array) {
    // æœªç›£è½æ™‚æª¢æŸ¥å–šé†’è©
    if (!isListening) {
      const wwResult = await WebASRCore.processWakewordChunk(
        wwResources,
        wwState,
        chunk,
        { threshold: config.wakeword.hey_jarvis.threshold }
      );
      wwState = wwResult.state;
      
      if (wwResult.triggered) {
        console.log('æª¢æ¸¬åˆ°å–šé†’è©ï¼é–‹å§‹ç›£è½...');
        isListening = true;
        audioBuffer.length = 0;
        wwState = WebASRCore.resetWakewordState(wwResources.dims);
      }
      return;
    }
    
    // ä½¿ç”¨ VAD æª¢æ¸¬èªéŸ³
    const vadResult = await WebASRCore.processVad(
      vadSession,
      vadState,
      chunk,
      WebASRCore.DEFAULT_VAD_PARAMS
    );
    vadState = vadResult.state;
    
    // èªéŸ³æ´»å‹•æ™‚æ”¶é›†éŸ³è¨Š
    if (vadResult.detected || vadState.isSpeechActive) {
      audioBuffer.push(chunk);
    }
    
    // èªéŸ³çµæŸæ™‚é€²è¡Œè½‰éŒ„
    if (!vadState.isSpeechActive && audioBuffer.length > 0) {
      // åˆä½µéŸ³è¨Šå¡Š
      const totalLength = audioBuffer.reduce((sum, chunk) => sum + chunk.length, 0);
      const combinedAudio = new Float32Array(totalLength);
      let offset = 0;
      for (const chunk of audioBuffer) {
        combinedAudio.set(chunk, offset);
        offset += chunk.length;
      }
      
      // è½‰éŒ„
      const result = await WebASRCore.transcribe(
        whisperResources,
        combinedAudio,
        { language: 'zh' }
      );
      
      console.log('æ‚¨èªªï¼š', result.text);
      
      // é‡è¨­ä»¥é€²è¡Œä¸‹æ¬¡äº’å‹•
      audioBuffer.length = 0;
      isListening = false;
    }
  }
  
  return { processAudioChunk };
}

// èˆ‡ Web Audio API é…åˆä½¿ç”¨
async function startRecording() {
  const assistant = await createVoiceAssistant();
  
  // å–å¾—éº¥å…‹é¢¨æ¬Šé™ï¼ˆé—œé–‰éŸ³è¨Šè™•ç†ä»¥ç²å¾—åŸå§‹éŸ³è¨Šï¼‰
  const stream = await navigator.mediaDevices.getUserMedia({ 
    audio: {
      channelCount: 1,
      sampleRate: 16000,
      echoCancellation: false,
      noiseSuppression: false,
      autoGainControl: false
    }
  });
  
  const audioContext = new AudioContext({ sampleRate: 16000 });
  const source = audioContext.createMediaStreamSource(stream);
  
  // å»ºç«‹è™•ç†å™¨è™•ç† 80ms å¡Š
  const processor = audioContext.createScriptProcessor(1280, 1, 1);
  
  processor.onaudioprocess = async (e) => {
    const inputData = e.inputBuffer.getChannelData(0);
    await assistant.processAudioChunk(new Float32Array(inputData));
  };
  
  source.connect(processor);
  processor.connect(audioContext.destination);
}
```

## API åƒè€ƒ

### è¨»å†Šè¡¨å‡½æ•¸

- `loadRegistry(url)`: å¾ JSON è¼‰å…¥æ¨¡å‹è¨»å†Šè¡¨
- `resolveVad(registry)`: å–å¾— VAD æ¨¡å‹é…ç½®
- `resolveWakeword(registry, id?)`: å–å¾—å–šé†’è©æ¨¡å‹é…ç½®
- `resolveWhisper(registry, id?)`: å–å¾— Whisper æ¨¡å‹é…ç½®
- `getAvailableModels(registry, type)`: åˆ—å‡ºå¯ç”¨æ¨¡å‹

### VAD æœå‹™

- `loadVadSession(modelUrl, options?)`: è¼‰å…¥ VAD æ¨¡å‹
- `createVadState()`: å»ºç«‹åˆå§‹ VAD ç‹€æ…‹
- `processVad(session, state, audio, params)`: è™•ç†éŸ³è¨Šé€²è¡Œ VAD
- `processVadChunks(session, chunks, state, params)`: è™•ç†å¤šå€‹éŸ³è¨Šå¡Š

### å–šé†’è©æœå‹™

- `loadWakewordResources(wakewordName, config?, customPaths?)`: è¼‰å…¥æ‰€æœ‰å–šé†’è©æ¨¡å‹
- `detectWakewordDims(resources, config?)`: æª¢æ¸¬æ¨¡å‹ç¶­åº¦
- `createWakewordState(dims)`: å»ºç«‹åˆå§‹ç‹€æ…‹
- `processWakewordChunk(resources, state, audio, params, config?)`: è™•ç†éŸ³è¨Š
- `resetWakewordState(dims)`: æª¢æ¸¬å¾Œé‡è¨­ç‹€æ…‹
- `createDefaultWakewordParams(wakewordName, config?)`: å»ºç«‹é è¨­åƒæ•¸

### Whisper æœå‹™

- `loadWhisperResources(modelPath, options?)`: è¼‰å…¥ Whisper æ¨¡å‹
- `transcribe(resources, audio, options?)`: è½‰éŒ„éŸ³è¨Š
- `transcribeChunks(resources, chunks, options?)`: è½‰éŒ„å¤šå€‹éŸ³è¨Šå¡Š

### é…ç½®ç®¡ç†

```typescript
import { ConfigManager } from 'web-asr-core';

const config = new ConfigManager();

// è‡ªè¨‚ VAD åƒæ•¸
config.vad.threshold = 0.6;
config.vad.minSilenceDuration = 1000;

// è‡ªè¨‚å–šé†’è©åƒæ•¸
config.wakeword.hey_jarvis.threshold = 0.5;
config.wakeword.common.melFramesPerChunk = 5;

// è‡ªè¨‚ Whisper åƒæ•¸
config.whisper.temperature = 0.2;
config.whisper.maxLength = 448;
```

## æ¨¡å‹é…ç½®

æ¨¡å‹é€é `global_registry.json` é…ç½®ã€‚è¨»å†Šè¡¨å®šç¾©å¯ç”¨æ¨¡å‹åŠå…¶è·¯å¾‘ï¼š

```json
{
  "version": "1.0.0",
  "models": [
    {
      "id": "silero-vad",
      "type": "vad",
      "local_path": "silero_vad.onnx"
    },
    {
      "id": "hey-jarvis",
      "type": "wakeword",
      "local_path": "hey_jarvis_v0.1.onnx",
      "files": {
        "required": [
          "melspectrogram.onnx",
          "embedding_model.onnx"
        ]
      }
    },
    {
      "id": "whisper-base",
      "type": "asr",
      "local_path": "huggingface/Xenova/whisper-base"
    }
  ]
}
```

## ç³»çµ±éœ€æ±‚

- æ”¯æ´ WebAssembly çš„ç¾ä»£ç€è¦½å™¨
- ONNX Runtime Web ç”¨æ–¼æ¨¡å‹æ¨ç†
- transformers.js ç”¨æ–¼ Whisper æ¨¡å‹
- 16kHz å–æ¨£ç‡çš„éŸ³è¨Šè¼¸å…¥

## æ¶æ§‹è¨­è¨ˆ

æ‰€æœ‰æœå‹™éµå¾ªç„¡ç‹€æ…‹ã€å‡½æ•¸å¼è¨­è¨ˆï¼š

1. **è³‡æºï¼ˆResourcesï¼‰**ï¼šæ¨¡å‹æœƒè©±/ç®¡ç·šè¼‰å…¥ä¸€æ¬¡ä¸¦é‡è¤‡ä½¿ç”¨
2. **ç‹€æ…‹ï¼ˆStateï¼‰**ï¼šç”±å‘¼å«è€…ç¶­è­·ï¼Œåœ¨å‡½æ•¸å‘¼å«ä¹‹é–“å‚³é
3. **è™•ç†ï¼ˆProcessingï¼‰**ï¼šç´”å‡½æ•¸ (resources, state, input) â†’ (result, newState)
4. **ç„¡å‰¯ä½œç”¨**ï¼šæ²’æœ‰å…¨åŸŸç‹€æ…‹æˆ–å…§éƒ¨è®Šæ›´

## æ•ˆèƒ½

- **VAD**ï¼šæ¯ 80ms å¡Šç´„ 5ms
- **å–šé†’è©**ï¼šæ¯ 80ms å¡Šç´„ 20-30ms
- **Whisper**ï¼š10 ç§’éŸ³è¨Šç´„ 1-3 ç§’ï¼ˆè¦–æ¨¡å‹å¤§å°è€Œå®šï¼‰

## ç€è¦½å™¨ç›¸å®¹æ€§

- Chrome/Edgeï¼šå®Œå…¨æ”¯æ´ï¼ˆå»ºè­°ä½¿ç”¨ï¼‰
- Firefoxï¼šå®Œå…¨æ”¯æ´
- Safariï¼šå¯¦é©—æ€§æ”¯æ´ï¼ˆæŸäº›åŠŸèƒ½å¯èƒ½å—é™ï¼‰

## å·²çŸ¥å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### éŸ³è¨Šç¸®æ”¾å•é¡Œ

å¦‚æœé‡åˆ°å–šé†’è©åœ¨éœéŸ³æ™‚èª¤è§¸ç™¼ï¼ˆé«˜åˆ†æ•¸ä½†ä½ RMSï¼‰ï¼Œé€šå¸¸æ˜¯éŸ³è¨Šç¸®æ”¾å•é¡Œï¼š

1. **é—œé–‰ç€è¦½å™¨éŸ³è¨Šè™•ç†**ï¼š
```javascript
getUserMedia({
  audio: {
    echoCancellation: false,
    noiseSuppression: false,
    autoGainControl: false
  }
})
```

2. **é©—è­‰å¯¦éš›è¨­å®š**ï¼š
```javascript
const settings = audioTrack.getSettings();
console.log('éŸ³è¨Šè¨­å®šï¼š', settings);
```

3. **æª¢æŸ¥éŸ³è¨Šå¥åº·ç‹€æ…‹**ï¼š
æ­£å¸¸èªªè©±æ™‚ maxAbs æ‡‰è©² > 0.01ï¼ŒdBFS æ‡‰è©²åœ¨ -40 åˆ° -20 ä¹‹é–“ã€‚

## æˆæ¬Š

MIT

## è²¢ç»

æ­¡è¿è²¢ç»ï¼è«‹éš¨æ™‚æäº¤å•é¡Œæˆ–æ‹‰å–è«‹æ±‚ã€‚

## è‡´è¬

- [Silero VAD](https://github.com/snakers4/silero-vad) æä¾› VAD æ¨¡å‹
- [OpenWakeWord](https://github.com/dscripka/openWakeWord) æä¾›å–šé†’è©æ¨¡å‹
- [Whisper](https://github.com/openai/whisper) å’Œ [transformers.js](https://github.com/xenova/transformers.js) æä¾›èªéŸ³è­˜åˆ¥