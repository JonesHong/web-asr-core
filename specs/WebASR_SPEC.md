# WebASR å‰ç«¯èªéŸ³è¾¨è­˜ç®¡ç·šå®Œæ•´è¦æ ¼æ›¸ v2.0

## 1. å°ˆæ¡ˆæ¦‚è¿°

WebASR æ˜¯ä¸€å€‹ç´”å‰ç«¯ã€å¯é€é CDN éƒ¨ç½²çš„èªéŸ³è¾¨è­˜ç®¡ç·šæ¡†æ¶ï¼Œæ”¯æ´å®Œå…¨é›¢ç·šé‹ä½œã€‚æ¡ç”¨æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œæ•´åˆ Wake Word åµæ¸¬ã€VADï¼ˆèªéŸ³æ´»å‹•åµæ¸¬ï¼‰ã€ä»¥åŠ Whisper èªéŸ³è½‰æ–‡å­—ç­‰åŠŸèƒ½ã€‚

### æ ¸å¿ƒç‰¹æ€§
- ğŸŒ **ç´”å‰ç«¯é‹ä½œ**ï¼šç„¡éœ€å¾Œç«¯æœå‹™ï¼Œå¯å®Œå…¨é›¢ç·šä½¿ç”¨
- ğŸ“¦ **CDN å‹å–„**ï¼šæ”¯æ´ ESM/UMD/IIFE å¤šç¨®è¼‰å…¥æ–¹å¼
- ğŸš€ **ç¡¬é«”åŠ é€Ÿ**ï¼šå„ªå…ˆä½¿ç”¨ WebGPUï¼Œè‡ªå‹•é™ç´šè‡³ WebGL/WASM
- ğŸ”§ **æ¨¡çµ„åŒ–æ¶æ§‹**ï¼šå¯å½ˆæ€§çµ„åˆä¸åŒåŠŸèƒ½æ¨¡çµ„
- ğŸ“Š **è¨ºæ–·ç³»çµ±**ï¼šè‡ªå‹•åµæ¸¬ç’°å¢ƒä¸¦æä¾›æœ€ä½³é…ç½®å»ºè­°

### âš ï¸ é‡è¦é™åˆ¶
- **SharedArrayBuffer éœ€è¦ç‰¹æ®Šç’°å¢ƒ**ï¼šå¿…é ˆè¨­å®š COOP/COEP HTTP Headers

## 2. ç³»çµ±æ¶æ§‹

```
â”Œâ”€ WebASR (EventTarget + FSM)
â”‚   .add(AudioQueue) .add(OpenWakeWord) .add(VAD) .add(Whisper)
â”‚   .on('wake_activated' | 'vad_speech_detected' | 'transcribe_done' | ...)
â”‚   .diagnosis()  // ç’°å¢ƒåµæ¸¬èˆ‡é…ç½®å»ºè­°
â”‚
â”œâ”€ AudioQueue   : getUserMedia + AudioWorklet (SharedArrayBuffer/RingBuffer)
â”œâ”€ OpenWakeWord : onnxruntime-web (WebGPU/WebNN/WebGL/WASM)
â”œâ”€ VAD          : onnxruntime-web + Silero VAD
â”œâ”€ Whisper      : Transformers.js (æ”¯æ´ WebGPU/WASM)
â”œâ”€ WebSpeech    : ç€è¦½å™¨åŸç”Ÿ API
â””â”€ Recorder     : MediaRecorderï¼ˆå¾ªç’°ç·©è¡æœ€è¿‘ 20 æ®µï¼‰
```

## 3. ç‹€æ…‹æ©Ÿè¨­è¨ˆ (FSM)

### ç‹€æ…‹å®šç¾©
```
States:
  idle              â†’ åˆå§‹/å¾…æ©Ÿç‹€æ…‹
  requesting_mic    â†’ è«‹æ±‚éº¥å…‹é¢¨æ¬Šé™
  listening         â†’ ç›£è½ä¸­ï¼ˆç­‰å¾…å–šé†’è©ï¼‰
  waking           â†’ å–šé†’è©è§¸ç™¼
  recording        â†’ éŒ„éŸ³ä¸­
  transcribing     â†’ èªéŸ³è½‰æ–‡å­—è™•ç†ä¸­
  webspeech        â†’ Web Speech API é™ç´šæ¨¡å¼
  error            â†’ éŒ¯èª¤ç‹€æ…‹
  paused           â†’ æš«åœç‹€æ…‹
  loading          â†’ æ¨¡å‹è¼‰å…¥ä¸­ï¼ˆä¾†è‡ªå¯¦ä½œç¶“é©—ï¼‰
```

### å¯¦ä½œç¶“é©—ï¼šäº‹ä»¶é©…å‹•ç‹€æ…‹ç®¡ç†
```javascript
// åŸºæ–¼å¯¦éš›å°ˆæ¡ˆçš„ FSM å¯¦ä½œæ¨¡å¼
class FiniteStateMachine extends EventTarget {
  constructor(initialState) {
    super();
    this.currentState = initialState;
    this.transitions = new Map();
    this.stateHandlers = new Map();
  }
  
  transition(event) {
    const key = `${this.currentState}:${event}`;
    const nextState = this.transitions.get(key);
    
    if (nextState) {
      const prevState = this.currentState;
      this.currentState = nextState;
      
      // ç™¼é€ç‹€æ…‹è®Šæ›´äº‹ä»¶
      this.dispatchEvent(new CustomEvent('state_changed', {
        detail: { from: prevState, to: nextState, event }
      }));
      
      // åŸ·è¡Œé€²å…¥ç‹€æ…‹çš„è™•ç†å™¨
      const handler = this.stateHandlers.get(nextState);
      if (handler) handler();
    }
  }
}
```

### ç‹€æ…‹è½‰æ›
```typescript
const transitions = {
  idle: {
    START: 'requesting_mic',
    RESET: 'idle'
  },
  requesting_mic: {
    MIC_GRANTED: 'listening',
    MIC_DENIED: 'error',
    MIC_REVOKED: 'requesting_mic'
  },
  listening: {
    WAKE_DETECTED: 'waking',
    PAUSE: 'paused',
    ERROR: 'error'
  },
  waking: {
    VAD_SPEECH: 'recording',
    WAKE_TIMEOUT: 'listening',
    ERROR: 'error'
  },
  recording: {
    VAD_SILENCE: 'transcribing',
    MAX_DURATION: 'transcribing',
    CANCEL: 'listening'
  },
  transcribing: {
    ASR_DONE: 'listening',
    ASR_ERROR: 'error',
    FALLBACK: 'webspeech'
  },
  webspeech: {
    RECOGNITION_DONE: 'listening',
    RECOGNITION_ERROR: 'error',
    CANCEL: 'listening'
  },
  error: {
    RETRY: 'requesting_mic',
    RESET: 'idle',
    DEGRADED_GPU: 'listening'
  },
  paused: {
    RESUME: 'listening',
    RESET: 'idle'
  }
};
```

## 4. API è¨­è¨ˆ

### 4.1 åŸºç¤ç”¨æ³•

```javascript
// ESM è¼‰å…¥
import { WebASR, AudioQueue, OpenWakeWord, VAD, Whisper } from 'https://cdn.jsdelivr.net/npm/web-asr@2.0.0/dist/web-asr.esm.js';

// UMD å…¨åŸŸè¼‰å…¥
<script src="https://cdn.jsdelivr.net/npm/web-asr@2.0.0/dist/web-asr.umd.js"></script>
```

### 4.2 åˆå§‹åŒ–é…ç½®

```javascript
// å¯¦ä½œç¶“é©—ï¼šé›†ä¸­å¼é…ç½®ç®¡ç†
class ConfigManager {
  constructor() {
    this.config = this.loadConfig();
  }
  
  loadConfig() {
    // ç’°å¢ƒåµæ¸¬ï¼ˆä¾†è‡ª config.js å¯¦ä½œï¼‰
    const isGitHubPages = window.location.hostname.includes('github.io');
    const isLocalhost = window.location.hostname === 'localhost' || 
                       window.location.hostname === '127.0.0.1';
    
    return {
      environment: isGitHubPages ? 'github' : (isLocalhost ? 'local' : 'production'),
      modelRegistry: isGitHubPages ? '/models/global_registry_github.json' : 
                                    '/models/global_registry.json',
      // å…¶ä»–é…ç½®...
    };
  }
}

const config = {
  audio: {
    sampleRate: 16000,
    channelCount: 1,
    echoCancellation: true,
    noiseSuppression: true,
  wakeword: {
    threshold: 0.5,  // 0-1 ç¯„åœ
    models: ['hey_jarvis'],
  },
  vad: {
    threshold: 0.6,
    silenceMs: 1500,
    speechMs: 250
  },
  whisper: {
    model: 'Xenova/whisper-tiny.en',
    device: 'auto',  // 'webgpu' | 'wasm' | 'auto'
    streaming: true,
    language: 'en',
    quantized: true  // WASM ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬
  },
  recorder: {
    maxClips: 20,
    format: 'auto'  // è‡ªå‹•åµæ¸¬æœ€ä½³æ ¼å¼
  },
  ringBuffer: {
    overflowPolicy: 'drop-oldest',  // 'drop-oldest' | 'block' | 'backpressure'
    size: 16384
  }
};

// çµ„è£ç®¡ç·š
const asr = new WebASR(config)
  .add(new AudioQueue({ 
    sampleRate: 16000, 
    useSharedArrayBuffer: window.crossOriginIsolated 
  }))
  .add(new VAD({ 
    threshold: 0.6,
    modelPath: '/models/silero_vad.onnx'
  }))
  .add(new Whisper({ 
    model: 'Xenova/whisper-tiny.en',
    device: 'auto'
  }));

if (config.wakeword) {
  asr.add(new OpenWakeWord({ 
    threshold: 0.5,
    modelPath: '/models/hey_jarvis.onnx'
  }));
}
```

### 4.3 äº‹ä»¶ç³»çµ±

```javascript
// æ ¸å¿ƒäº‹ä»¶
asr.on('state_changed', (e) => {
  console.log(`State: ${e.detail.from} â†’ ${e.detail.to}`);
});

asr.on('wake_activated', () => {
  console.log('å–šé†’è©è§¸ç™¼');
});

asr.on('vad_speech_start', () => {
  console.log('åµæ¸¬åˆ°èªéŸ³é–‹å§‹');
});

asr.on('vad_speech_end', () => {
  console.log('åµæ¸¬åˆ°èªéŸ³çµæŸ');
});

asr.on('transcribe_partial', (e) => {
  console.log('éƒ¨åˆ†çµæœ:', e.detail.text);
});

asr.on('transcribe_done', (e) => {
  console.log('å®Œæ•´çµæœ:', e.detail.text, 'RT Factor:', e.detail.rtFactor);
});

// æ•ˆèƒ½èˆ‡éŒ¯èª¤äº‹ä»¶
asr.on('model_progress', (e) => {
  console.log(`æ¨¡å‹è¼‰å…¥é€²åº¦: ${e.detail.loaded}/${e.detail.total}`);
});

asr.on('buffer_overflow', () => {
  console.warn('éŸ³è¨Šç·©è¡å€æº¢å‡º');
});

asr.on('backpressure', (e) => {
  console.warn('èƒŒå£“è­¦å‘Š:', e.detail.pressure);
});

asr.on('ep_fallback', (e) => {
  console.warn(`åŸ·è¡Œæä¾›è€…é™ç´š: ${e.detail.from} â†’ ${e.detail.to}`);
});

asr.on('error', (e) => {
  console.error('éŒ¯èª¤:', e.detail.code, e.detail.message);
});
```

## 5. è¨ºæ–·ç³»çµ±ï¼ˆå¢å¼·ç‰ˆï¼‰

### 5.0 å¯¦ä½œç¶“é©—ï¼šè¼‰å…¥ç®¡ç†å™¨
```javascript
// ä¾†è‡ª loading-manager.js çš„å…¨è¢å¹•è¼‰å…¥é«”é©—
class LoadingManager {
  constructor() {
    this.overlay = null;
    this.loadingSteps = [];
    this.currentStep = 0;
  }
  
  show(message = 'Loading...') {
    if (!this.overlay) {
      this.overlay = document.createElement('div');
      this.overlay.className = 'loading-overlay';
      this.overlay.innerHTML = `
        <div class="loading-container">
          <div class="loading-spinner"></div>
          <div class="loading-message">${message}</div>
          <div class="loading-progress">
            <div class="loading-progress-bar"></div>
          </div>
        </div>
      `;
      document.body.appendChild(this.overlay);
    }
  }
  
  updateProgress(percent, message) {
    if (this.overlay) {
      const progressBar = this.overlay.querySelector('.loading-progress-bar');
      const messageEl = this.overlay.querySelector('.loading-message');
      progressBar.style.width = `${percent}%`;
      messageEl.textContent = message;
    }
  }
  
  hide() {
    if (this.overlay) {
      this.overlay.classList.add('fade-out');
      setTimeout(() => {
        this.overlay?.remove();
        this.overlay = null;
      }, 300);
    }
  }
}

// æ¨¡å‹é è¼‰å…¥ç­–ç•¥ï¼ˆä¾†è‡ª model-preloader.jsï¼‰
class ModelPreloader {
  constructor() {
    this.preloadQueue = [];
    this.loadedModels = new Set();
  }
  
  async preloadModels(modelList) {
    // ä½¿ç”¨ prefetch æç¤ºç€è¦½å™¨é è¼‰å…¥
    for (const model of modelList) {
      const link = document.createElement('link');
      link.rel = 'prefetch';
      link.as = 'fetch';
      link.href = model.url;
      link.crossOrigin = 'anonymous';
      document.head.appendChild(link);
    }
    
    // å¯¦éš›è¼‰å…¥æ™‚ä½¿ç”¨ Cache API
    if ('caches' in window) {
      const cache = await caches.open('models-v1');
      for (const model of modelList) {
        if (!this.loadedModels.has(model.id)) {
          const response = await fetch(model.url);
          await cache.put(model.url, response.clone());
          this.loadedModels.add(model.id);
        }
      }
    }
  }
}
```

## 5. è¨ºæ–·ç³»çµ±ï¼ˆå¢å¼·ç‰ˆï¼‰

```typescript
interface Diagnosis {
  supported: {
    secureContext: boolean;
    getUserMedia: boolean;
    audioWorklet: boolean;
    sharedArrayBuffer: boolean;
    crossOriginIsolated: boolean;  // æ–°å¢
    webgpu: boolean;
    webgl: boolean;
    webnn: boolean;
    webgpuInWorker: boolean;  // æ–°å¢
    wasmThreads: boolean;
    wasmSIMD: boolean;
    mediaRecorder: boolean;
    mediaRecorderMimes: string[];  // æ–°å¢
    webSpeechRecognition: boolean;
    webSpeechOffline: boolean;  // æ–°å¢
    cacheAPI: boolean;
    indexedDB: boolean;
  };
  performance: {
    gpuTier: 'high' | 'medium' | 'low';
    memoryGB: number;
    cpuCores: number;
  };
  recommendation: {
    executionProvider: ('webgpu' | 'webnn' | 'webgl' | 'wasm')[];
    whisperBackend: 'webgpu' | 'wasm';
    transport: 'sab' | 'messageport';
    audioConfig: {
      chunkMs: number;
      bufferSizeFrames: number;
    };
    modelSize: 'tiny' | 'base' | 'small';
    mediaRecorderMime: string;  // æ–°å¢
    headersNeeded?: {
      COOP: string;
      COEP: string;
    };
    notes: string[];
    warnings: string[];  // æ–°å¢
  };
}
async function detectWasmFeatures() {
  const simd = WebAssembly.validate(
    new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,10,1,8,0,65,0,253,98,26,11])
  );
  let threads = false;
  try {
    // å˜—è©¦å»ºç«‹ Shared Memory ä»¥åµæ¸¬ threads å¯ç”¨ï¼ˆéœ€ crossOriginIsolatedï¼‰
    new WebAssembly.Memory({ initial: 1, maximum: 1, shared: true });
    threads = true;
  } catch {}
  return { wasmSIMD: simd, wasmThreads: threads };
}
function pickAudioMime(): string {
  const candidates = [
    'audio/webm;codecs=opus', // Chromium/Firefox
    'audio/mp4',              // Safari (AAC)
    'audio/mp4;codecs=alac',  // æ–°çš„ Safari TP å¯éŒ„ ALACï¼ˆé è¦½ç‰ˆï¼‰
    'audio/wav'               // æœ€ä¿å®ˆï¼ˆéƒ¨åˆ†ç€è¦½å™¨ä¸æ”¯æ´ MediaRecorder çš„ wavï¼‰
  ];
  for (const m of candidates) {
    if ('MediaRecorder' in self && MediaRecorder.isTypeSupported(m)) return m;
  }
  throw new Error('No supported audio container/codec for MediaRecorder on this browser');
}
// main thread
async function detectWebGPUInWorker(): Promise<boolean> {
  return new Promise((resolve) => {
    const w = new Worker(new URL('./gpu-probe.worker.js', import.meta.url), { type: 'module' });
    const t = setTimeout(() => (w.terminate(), resolve(false)), 1000);
    w.onmessage = (e) => { clearTimeout(t); w.terminate(); resolve(!!e.data?.gpu); };
  });
}

// gpu-probe.worker.js
self.postMessage({ gpu: 'gpu' in self.navigator });

export async function diagnosis(): Promise<Diagnosis> {
  const httpsOK = location.protocol === 'https:' || location.hostname === 'localhost';
  const coiOK   = !!self.crossOriginIsolated;

  const hasSAB  = typeof SharedArrayBuffer !== 'undefined' && coiOK;
  const webgpu  = 'gpu' in navigator;
  const webgl   = !!document.createElement('canvas').getContext('webgl2');
  const webnn   = 'ml' in navigator; // éœ€å®‰å…¨ä¸Šä¸‹æ–‡ï¼Œä¸»è¦ Chromium ç³»
  const webSpeech = ('webkitSpeechRecognition' in self) || ('SpeechRecognition' in self);

  // Worker å…§æª¢æŸ¥ WebGPU
  const webgpuInWorker = await detectWebGPUInWorker();

  // MediaRecorder mime å”å•†
  let mrOK = false, mrMime = '';
  try { mrMime = pickAudioMime(); mrOK = !!mrMime; } catch {}

  const { wasmSIMD, wasmThreads } = httpsOK && coiOK ? await detectWasmFeatures() : { wasmSIMD: false, wasmThreads: false };

  return {
    httpsOK,
    crossOriginIsolated: coiOK,
    webgpu, webgpuInWorker, webgl, webnn,
    sharedArrayBuffer: hasSAB,
    wasmSIMD, wasmThreads,
    mediaRecorder: mrOK, mediaRecorderMime: mrMime,
    webSpeechApi: webSpeech,
    // æ¨è–¦è¨­å®šï¼š
    recommended: {
      ep: webgpu ? 'webgpu' : 'wasm',
      dtype: webgpu ? 'fp16' : 'q8',
      useWorkers: true,
      recordMimeType: mrMime || 'audio/webm;codecs=opus',
      caution: !httpsOK ? 'éœ€è¦ HTTPS/localhost æ‰èƒ½ç”¨é€²éšåŠŸèƒ½' :
               !coiOK   ? 'è«‹æ­£ç¢ºè¨­ç½® COOP/COEP å›æ‡‰æ¨™é ­ä»¥å•Ÿç”¨ SAB/wasm-threads' : ''
    }
  };
}

```

## 6. æ ¸å¿ƒæ¨¡çµ„å¯¦ä½œ

### 6.1 AudioQueue with RingBuffer æ”¿ç­–

#### å¯¦ä½œç¶“é©—ï¼šéŸ³é »ç®¡ç·šæ•´åˆ
```javascript
// ä¾†è‡ª audio-pipeline-integration.js çš„å¯¦æˆ°ç¶“é©—
class AudioPipelineIntegration {
  constructor() {
    this.audioContext = null;
    this.source = null;
    this.workletNode = null;
  }
  
  async initialize(stream) {
    // è™•ç†ç€è¦½å™¨ç›¸å®¹æ€§ï¼ˆä¾†è‡ª audio-compatibility-manager.jsï¼‰
    const AudioContextClass = window.AudioContext || window.webkitAudioContext;
    this.audioContext = new AudioContextClass({ sampleRate: 16000 });
    
    // è™•ç† Safari çš„ AudioContext é™åˆ¶
    if (this.audioContext.state === 'suspended') {
      await this.audioContext.resume();
    }
    
    // è¼‰å…¥ AudioWorklet
    try {
      await this.audioContext.audioWorklet.addModule('/js/worklets/audio-processor.worklet.js');
    } catch (error) {
      console.warn('AudioWorklet è¼‰å…¥å¤±æ•—ï¼Œé™ç´šè‡³ ScriptProcessor');
      return this.fallbackToScriptProcessor(stream);
    }
    
    this.source = this.audioContext.createMediaStreamSource(stream);
    this.workletNode = new AudioWorkletNode(this.audioContext, 'audio-processor', {
      processorOptions: {
        bufferSize: 1280,  // 80ms at 16kHz
        targetSampleRate: 16000
      }
    });
    
    // é€£æ¥éŸ³é »åœ–
    this.source.connect(this.workletNode);
    
    // è™•ç†ä¾†è‡ª worklet çš„è³‡æ–™
    this.workletNode.port.onmessage = (event) => {
      if (event.data.type === 'audio') {
        this.handleAudioData(event.data.buffer);
      }
    };
  }
  
  fallbackToScriptProcessor(stream) {
    // ScriptProcessor é™ç´šæ–¹æ¡ˆï¼ˆå·²æ£„ç”¨ä½†ç›¸å®¹æ€§è¼ƒå¥½ï¼‰
    const bufferSize = 4096;
    const processor = this.audioContext.createScriptProcessor(bufferSize, 1, 1);
    
    processor.onaudioprocess = (e) => {
      const inputData = e.inputBuffer.getChannelData(0);
      this.handleAudioData(inputData);
    };
    
    this.source = this.audioContext.createMediaStreamSource(stream);
    this.source.connect(processor);
    processor.connect(this.audioContext.destination);
  }
}
```

```javascript
class AudioQueue extends EventTarget {
  private ringBuffer?: RingBuffer;
  private overflowPolicy: 'drop-oldest' | 'block' | 'backpressure';
  
  constructor(options: AudioQueueOptions) {
    super();
    this.overflowPolicy = options.overflowPolicy || 'drop-oldest';
  }
  
  async start() {
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        channelCount: 1,
        sampleRate: 48000,  // è«‹æ±‚å€¼
        echoCancellation: true,
        noiseSuppression: true
      }
    });
    
    const ctx = new AudioContext();
    const actualSampleRate = ctx.sampleRate;  // å¯¦éš›å€¼
    
    this.resampler.configure({ 
      from: actualSampleRate, 
      to: 16000 
    });
    
    if (window.crossOriginIsolated) {
      // SAB è·¯å¾‘
      const sab = new SharedArrayBuffer(this.options.size || 16384);
      this.ringBuffer = new RingBuffer(sab, Float32Array);
    } else {
      // MessagePort é™ç´š
      console.warn('SharedArrayBuffer ä¸å¯ç”¨ï¼Œé™ç´šè‡³ MessagePort');
    }
  }
  
  private handleOverflow(dataSize: number) {
    switch (this.overflowPolicy) {
      case 'drop-oldest':
        const framesToDrop = Math.ceil(dataSize / this.frameSize);
        this.ringBuffer.dropFrames(framesToDrop);
        this.emit('buffer_overflow', { dropped: framesToDrop });
        break;
        
      case 'block':
        // ç­‰å¾…ç©ºé–“é‡‹æ”¾
        return false;
        
      case 'backpressure':
        // ç™¼å‡ºèƒŒå£“è¨Šè™Ÿ
        this.emit('back_pressure', { 
          pressure: this.ringBuffer.usage(),
          recommendation: 'reduce_rate' 
        });
        break;
    }
    return true;
  }
}
```

### 6.2 OpenWakeWord with EP å›é€€

#### å¯¦ä½œç¶“é©—ï¼šWorker æ•´åˆæ¨¡å¼
```javascript
// ä¾†è‡ª worker-integrated-wakeword.js çš„å¯¦æˆ°æ¨¡å¼
class WorkerIntegratedWakeWord {
  constructor() {
    this.worker = null;
    this.modelLoaded = false;
  }
  
  async initialize() {
    // å»ºç«‹ Worker
    this.worker = new Worker('/js/workers/ml-inference.worker.js', { type: 'module' });
    
    // Worker è¨Šæ¯è™•ç†æ¨¡å¼
    return new Promise((resolve, reject) => {
      const messageHandler = (event) => {
        const { type, data, error } = event.data;
        
        switch (type) {
          case 'model-loaded':
            this.modelLoaded = true;
            resolve();
            break;
            
          case 'inference-result':
            this.handleDetection(data);
            break;
            
          case 'error':
            console.error('Worker error:', error);
            reject(error);
            break;
        }
      };
      
      this.worker.addEventListener('message', messageHandler);
      
      // è¼‰å…¥æ¨¡å‹
      this.worker.postMessage({
        type: 'load-model',
        modelPath: '/models/hey_jarvis_v0.1.onnx',
        options: {
          executionProvider: this.selectBestProvider()
        }
      });
    });
  }
  
  selectBestProvider() {
    // å¯¦æˆ°ç¶“é©—ï¼šåŸ·è¡Œæä¾›è€…é¸æ“‡ç­–ç•¥
    if ('gpu' in navigator) {
      // æª¢æŸ¥ WebGPU æ”¯æ´
      return { name: 'webgpu', deviceType: 'gpu' };
    } else if (document.createElement('canvas').getContext('webgl2')) {
      // WebGL é™ç´š
      return { name: 'webgl' };
    } else {
      // WASM æœ€çµ‚é™ç´š
      return { name: 'wasm', numThreads: navigator.hardwareConcurrency || 4 };
    }
  }
}
```

```javascript
class OpenWakeWord extends EventTarget {
  private session?: ort.InferenceSession;
  private currentEP?: string;
  
  async init() {
    const providers = this.selectProviders();
    
    for (const provider of providers) {
      try {
        this.session = await ort.InferenceSession.create(
          this.options.modelPath,
          {
            executionProviders: [provider],
            graphOptimizationLevel: 'all'
          }
        );
        this.currentEP = provider;
        console.log(`OpenWakeWord ä½¿ç”¨ ${provider}`);
        break;
      } catch (err) {
        console.warn(`${provider} åˆå§‹åŒ–å¤±æ•—ï¼Œå˜—è©¦ä¸‹ä¸€å€‹`, err);
        this.emit('ep_fallback', { 
          from: provider, 
          to: providers[providers.indexOf(provider) + 1],
          reason: err.message 
        });
      }
    }
    
    if (!this.session) {
      throw new Error('æ‰€æœ‰åŸ·è¡Œæä¾›è€…éƒ½å¤±æ•—');
    }
  }
  
  private selectProviders(): string[] {
    const providers = [];
    
    // WebGPU
    if ((navigator as any).gpu) {
      providers.push('webgpu');
    }
    
    // WebNN (å¯¦é©—æ€§ï¼Œå®¹æ˜“å¤±æ•—)
    if ('ml' in navigator) {
      providers.push('webnn');
    }
    
    // WebGL
    if (document.createElement('canvas').getContext('webgl2')) {
      providers.push('webgl');
    }
    
    // WASM (æœ€å¾Œå‚™æ´)
    providers.push('wasm');
    
    return providers;
  }
  
  dispose() {
    if (this.session && typeof this.session.release === 'function') {
      this.session.release();
    }
    this.session = null;
  }
}
```

### 6.3 Whisper æ¨™æº–åŒ–é…ç½®

#### å¯¦ä½œç¶“é©—ï¼šé›™å¼•æ“ç®¡ç†
```javascript
// ä¾†è‡ª speech-recognition-manager.js çš„é›™å¼•æ“æ¨¡å¼
class SpeechRecognitionManager {
  constructor() {
    this.currentEngine = null;
    this.engines = new Map();
  }
  
  async initialize() {
    // è¨»å†Šå¯ç”¨å¼•æ“
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const WebSpeechEngine = (await import('/js/modules/engines/webspeech-engine.js')).default;
      this.engines.set('webspeech', new WebSpeechEngine());
    }
    
    // Whisper å¼•æ“
    const WhisperEngine = (await import('/js/modules/engines/whisper-engine.js')).default;
    this.engines.set('whisper', new WhisperEngine());
    
    // é¸æ“‡æœ€ä½³å¼•æ“
    this.selectEngine();
  }
  
  selectEngine() {
    // å¯¦æˆ°ç­–ç•¥ï¼šæ ¹æ“šç’°å¢ƒé¸æ“‡å¼•æ“
    const isOnline = navigator.onLine;
    const hasWebSpeech = this.engines.has('webspeech');
    
    if (isOnline && hasWebSpeech) {
      // ç·šä¸Šå„ªå…ˆä½¿ç”¨ Web Speech APIï¼ˆæ›´å¿«ï¼‰
      this.currentEngine = this.engines.get('webspeech');
    } else {
      // é›¢ç·šæˆ–ç„¡ Web Speech ä½¿ç”¨ Whisper
      this.currentEngine = this.engines.get('whisper');
    }
    
    // ç›£è½ç·šä¸Šç‹€æ…‹è®ŠåŒ–
    window.addEventListener('online', () => this.selectEngine());
    window.addEventListener('offline', () => this.selectEngine());
  }
  
  async transcribe(audioData) {
    try {
      return await this.currentEngine.transcribe(audioData);
    } catch (error) {
      // å¼•æ“å¤±æ•—æ™‚è‡ªå‹•åˆ‡æ›
      console.warn('Engine failed, switching...', error);
      this.switchEngine();
      return await this.currentEngine.transcribe(audioData);
    }
  }
  
  switchEngine() {
    const engines = Array.from(this.engines.values());
    const currentIndex = engines.indexOf(this.currentEngine);
    const nextIndex = (currentIndex + 1) % engines.length;
    this.currentEngine = engines[nextIndex];
  }
}
```

```javascript
class Whisper extends EventTarget {
  private pipeline?: any;
  
  async init() {
    const { pipeline, env } = await import('@xenova/transformers');
    
    // å•Ÿç”¨ç€è¦½å™¨å¿«å–ï¼ˆFile System / Cache APIï¼›ä¾ç’°å¢ƒè€Œå®šï¼‰
    env.useCache = true;
    
    // å¯é¸ï¼šè‡ªè¨‚ IndexedDB å¿«å–ï¼ˆéœ€å¯¦ä½œ Cache API ä»‹é¢ï¼‰
    if (this.options.customCache) {
      env.useCustomCache = true;
      env.customCache = this.options.customCache;
    }
    // è£ç½®é¸æ“‡
    const device = this.options.device === 'auto' ? 
      ((navigator as any).gpu ? 'webgpu' : 'wasm') : 
      this.options.device;
    // dtype ç­–ç•¥ï¼š
    // - WebGPU: è‡ªå‹•é¸æ“‡ï¼ˆå¯èƒ½æ˜¯ fp32/fp16 ä¾è£ç½®ï¼‰
    // - WASM: å„ªå…ˆä½¿ç”¨é‡åŒ–ç‰ˆæœ¬ä»¥æå‡æ•ˆèƒ½
    const dtype = device === 'webgpu' ? 'fp16' : 'q8' || this.options.dtype;
    // å»ºç«‹ç®¡ç·šï¼Œæ ¹æ“šè£ç½®è‡ªå‹•é¸æ“‡æœ€ä½³é…ç½®
    this.pipeline = await pipeline(
      'automatic-speech-recognition',
      this.options.model,
      {
        device: device,
        dtype: dtype,
        // é€²åº¦å›èª¿
        progress_callback: (progress) => {
          this.emit('model_progress', progress);
        }
        // å¯å‚³ session_options é€² ORT
      }
    );
    
    // ä¸²æµå™¨é…ç½®
    if (this.options.streaming) {
      const { WhisperTextStreamer } = await import('@xenova/transformers');
      this.streamer = new WhisperTextStreamer({
        skip_prompt: true,
        skip_special_tokens: true,
        callback_function: (text) => {
          this.emit('transcribe_partial', { text });
        }
      });
    }
  }
  
  dispose() {
    // ä½¿ç”¨å®˜æ–¹æä¾›çš„ dispose æ–¹æ³•
    this.pipeline?.dispose();
  }
}
```

## 7. éƒ¨ç½²è¦æ±‚

### 7.0 å¯¦ä½œç¶“é©—ï¼šæ¨¡å‹è¨»å†Šç³»çµ±
```javascript
// ä¾†è‡ª global_registry.json çš„å‹•æ…‹æ¨¡å‹ç®¡ç†
class ModelRegistry {
  constructor() {
    this.registry = null;
    this.modelCache = new Map();
  }
  
  async loadRegistry() {
    // æ ¹æ“šç’°å¢ƒè¼‰å…¥ä¸åŒçš„è¨»å†Šè¡¨
    const isGitHubPages = window.location.hostname.includes('github.io');
    const registryPath = isGitHubPages ? 
      '/models/global_registry_github.json' : 
      '/models/global_registry.json';
    
    const response = await fetch(registryPath);
    this.registry = await response.json();
    
    return this.registry;
  }
  
  getModelConfig(modelType, modelName) {
    // å¾è¨»å†Šè¡¨ç²å–æ¨¡å‹é…ç½®
    const models = this.registry[modelType];
    if (!models) throw new Error(`Unknown model type: ${modelType}`);
    
    const config = models[modelName];
    if (!config) throw new Error(`Unknown model: ${modelName}`);
    
    // è™•ç†ä¸åŒä¾†æº
    switch (config.source) {
      case 'huggingface':
        return {
          ...config,
          url: `https://huggingface.co/${config.repo}/resolve/main/${config.file}`
        };
        
      case 'github':
        return {
          ...config,
          url: config.url  // ç›´æ¥ä½¿ç”¨ GitHub è¨—ç®¡çš„ URL
        };
        
      case 'local':
        return {
          ...config,
          url: `/models/${config.file}`
        };
        
      default:
        return config;
    }
  }
  
  async downloadModel(modelType, modelName, progressCallback) {
    const config = this.getModelConfig(modelType, modelName);
    
    // æª¢æŸ¥å¿«å–
    if (this.modelCache.has(config.url)) {
      return this.modelCache.get(config.url);
    }
    
    // ä¸‹è¼‰æ¨¡å‹
    const response = await fetch(config.url);
    const contentLength = response.headers.get('content-length');
    
    if (contentLength && progressCallback) {
      // æ”¯æ´é€²åº¦å›èª¿
      const reader = response.body.getReader();
      const chunks = [];
      let receivedLength = 0;
      
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        chunks.push(value);
        receivedLength += value.length;
        
        progressCallback({
          loaded: receivedLength,
          total: parseInt(contentLength),
          percent: (receivedLength / parseInt(contentLength)) * 100
        });
      }
      
      const blob = new Blob(chunks);
      const arrayBuffer = await blob.arrayBuffer();
      
      // å¿«å–æ¨¡å‹
      this.modelCache.set(config.url, arrayBuffer);
      
      return arrayBuffer;
    } else {
      // ç°¡å–®ä¸‹è¼‰
      const arrayBuffer = await response.arrayBuffer();
      this.modelCache.set(config.url, arrayBuffer);
      return arrayBuffer;
    }
  }
}
```

## 7. éƒ¨ç½²è¦æ±‚

### 7.1 HTTP æ¨™é ­é…ç½®ï¼ˆå„å¹³å°æŒ‡å—ï¼‰

#### Nginx
```nginx
# å¿…é ˆåœ¨ HTTP Response è¨­å®šï¼Œmeta tags ç„¡æ•ˆï¼
add_header Cross-Origin-Opener-Policy "same-origin";
add_header Cross-Origin-Embedder-Policy "require-corp";
add_header Cross-Origin-Resource-Policy "cross-origin";
```

#### Apache
```apache
Header set Cross-Origin-Opener-Policy "same-origin"
Header set Cross-Origin-Embedder-Policy "require-corp" 
Header set Cross-Origin-Resource-Policy "cross-origin"
```

#### Cloudflare Workers
```javascript
export default {
  async fetch(request, env) {
    const response = await fetch(request);
    const newHeaders = new Headers(response.headers);
    
    newHeaders.set('Cross-Origin-Opener-Policy', 'same-origin');
    newHeaders.set('Cross-Origin-Embedder-Policy', 'require-corp');
    
    return new Response(response.body, {
      status: response.status,
      statusText: response.statusText,
      headers: newHeaders
    });
  }
};
```

#### Vercel
```javascript
// vercel.json
{
  "headers": [
    {
      "source": "/(.*)",
      "headers": [
        {
          "key": "Cross-Origin-Opener-Policy",
          "value": "same-origin"
        },
        {
          "key": "Cross-Origin-Embedder-Policy",
          "value": "require-corp"
        }
      ]
    }
  ]
}
```

#### Netlify
```toml
# netlify.toml
[[headers]]
  for = "/*"
  [headers.values]
    Cross-Origin-Opener-Policy = "same-origin"
    Cross-Origin-Embedder-Policy = "require-corp"
```

### 7.2 MediaRecorder æ ¼å¼åµæ¸¬

```javascript
class Recorder {
  private getMimeType(): string {
    const formats = [
      'audio/webm;codecs=opus',
      'audio/webm',
      'audio/mp4',
      'audio/ogg;codecs=opus'
    ];
    
    for (const format of formats) {
      if (MediaRecorder.isTypeSupported(format)) {
        return format;
      }
    }
    
    // ç„¡æ”¯æ´æ ¼å¼ï¼ˆå¦‚ iOS Safari < 14.3ï¼‰
    console.warn('MediaRecorder ä¸æ”¯æ´æ¨™æº–æ ¼å¼ï¼Œä½¿ç”¨ PCM fallback');
    return '';
  }
  
  start(stream: MediaStream) {
    const mimeType = this.getMimeType();
    
    if (!mimeType) {
      // ä½¿ç”¨ AudioWorklet ç›´æ¥éŒ„è£½ PCM
      this.usePCMFallback(stream);
      return;
    }
    
    this.recorder = new MediaRecorder(stream, { mimeType });
  }
}
```

## 8. è¨˜æ†¶é«”ç®¡ç†

```javascript
class MemoryManager {
  private readonly MAX_BUFFER_AGE = 5 * 60 * 1000;  // 5 åˆ†é˜
  private readonly CHECK_INTERVAL = 60 * 1000;      // æ¯åˆ†é˜
  
  start() {
    setInterval(() => this.cleanup(), this.CHECK_INTERVAL);
  }
  
  private cleanup() {
    const now = Date.now();
    
    // æ¸…ç†éæœŸç·©è¡å€
    this.buffers.forEach((buffer, id) => {
      if (now - buffer.timestamp > this.MAX_BUFFER_AGE) {
        this.buffers.delete(id);
      }
    });
    
    // é‡‹æ”¾ Blob URLs
    this.blobUrls.forEach(url => {
      if (now - url.timestamp > this.MAX_BUFFER_AGE) {
        URL.revokeObjectURL(url.url);
      }
    });
    
    // æª¢æŸ¥è¨˜æ†¶é«”å£“åŠ›ï¼ˆChrome onlyï¼‰
    if ((performance as any).memory?.usedJSHeapSize > 500 * 1024 * 1024) {
      console.warn('è¨˜æ†¶é«”ä½¿ç”¨éé«˜ï¼ŒåŸ·è¡Œç·Šæ€¥æ¸…ç†');
      this.emergencyCleanup();
    }
  }
}
```

## 9. å®Œæ•´ä½¿ç”¨ç¯„ä¾‹

### 9.0 å¯¦ä½œç¶“é©—ï¼šæ‰¹æ¬¡æ¨¡å¼è™•ç†
```javascript
// ä¾†è‡ªå¯¦éš›å°ˆæ¡ˆçš„é›™æ¨¡å¼æ”¯æ´
class DualModeProcessor {
  constructor() {
    this.mode = 'streaming';  // 'streaming' | 'batch'
    this.batchQueue = [];
  }
  
  setMode(mode) {
    this.mode = mode;
    this.emit('mode_changed', { mode });
  }
  
  // ä¸²æµæ¨¡å¼ï¼šå³æ™‚è™•ç†
  processStreaming(audioChunk) {
    // ç«‹å³è™•ç†æ¯å€‹éŸ³é »å¡Š
    this.wakewordDetector.process(audioChunk);
    this.vadDetector.process(audioChunk);
    
    if (this.isRecording) {
      this.audioBuffer.push(audioChunk);
    }
  }
  
  // æ‰¹æ¬¡æ¨¡å¼ï¼šæª”æ¡ˆä¸Šå‚³æˆ–éŒ„éŸ³
  async processBatch(audioFile) {
    // è§£ç¢¼éŸ³é »æª”æ¡ˆ
    const audioBuffer = await this.decodeAudioFile(audioFile);
    
    // åˆ†å‰²æˆå¡Šé€²è¡Œè™•ç†
    const chunkSize = 16000 * 30;  // 30 ç§’å¡Š
    const chunks = this.splitAudioBuffer(audioBuffer, chunkSize);
    
    const results = [];
    for (const chunk of chunks) {
      const result = await this.transcribeChunk(chunk);
      results.push(result);
      
      // æ›´æ–°é€²åº¦
      this.emit('batch_progress', {
        current: results.length,
        total: chunks.length,
        percent: (results.length / chunks.length) * 100
      });
    }
    
    return this.mergeResults(results);
  }
  
  async decodeAudioFile(file) {
    // ä½¿ç”¨ Web Audio API è§£ç¢¼
    const arrayBuffer = await file.arrayBuffer();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    
    // è½‰æ›ç‚º 16kHz å–®è²é“
    const targetSampleRate = 16000;
    const resampled = this.resampleAudioBuffer(audioBuffer, targetSampleRate);
    
    return resampled;
  }
}
```

## 9. å®Œæ•´ä½¿ç”¨ç¯„ä¾‹

```html
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>WebASR Demo</title>
  <!-- 
    é‡è¦ï¼šCOOP/COEP å¿…é ˆç”± HTTP Response Headers è¨­å®š
    ä¸èƒ½ä½¿ç”¨ meta tagsï¼è«‹åœ¨ä¼ºæœå™¨ç«¯è¨­å®šï¼š
    
    # å¼·éš”é›¢ï¼ˆæœ€åš´ï¼‰
    Cross-Origin-Opener-Policy: same-origin
    Cross-Origin-Embedder-Policy: require-corp

    # æˆ–ï¼šcredentialless è®Šé«”ï¼ˆå°ä¸å¸¶æ†‘è­‰çš„è·¨åŸŸè³‡æºè¼ƒå¯¬é¬†ï¼‰
    Cross-Origin-Opener-Policy: same-origin
    Cross-Origin-Embedder-Policy: credentialless
  -->
</head>
<body>
  <div id="status">æª¢æ¸¬ç’°å¢ƒä¸­...</div>
  <button id="start" disabled>é–‹å§‹</button>
  <div id="result"></div>
  
  <script type="module">
    import { WebASR, AudioQueue, VAD, Whisper } from './web-asr.esm.js';
    
    // è¨ºæ–·ç’°å¢ƒ
    const diagnosis = await WebASR.diagnosis();
    
    if (!diagnosis.supported.secureContext) {
      document.getElementById('status').textContent = 'éœ€è¦ HTTPS';
      throw new Error('éœ€è¦ HTTPS');
    }
    if (!self.crossOriginIsolated) {
      throw new Error('SharedArrayBuffer/wasm-threads ä¸å¯ç”¨ï¼šè«‹æ­£ç¢ºè¨­ç½® COOP/COEP å›æ‡‰æ¨™é ­');
    }
    
    // é…ç½®
    const config = {
      audio: {
        sampleRate: 16000,
        useSharedArrayBuffer: diagnosis.supported.sharedArrayBuffer,
        overflowPolicy: 'backpressure'
      },
      vad: {
        threshold: 0.6
      },
      whisper: {
        device: diagnosis.recommendation.whisperBackend,
        model: 'Xenova/whisper-tiny.en',
        streaming: true,
        quantized: diagnosis.recommendation.whisperBackend === 'wasm'
      }
    };
    
    // å»ºç«‹ç®¡ç·š
    const asr = new WebASR(config)
      .add(new AudioQueue(config.audio))
      .add(new VAD(config.vad))
      .add(new Whisper(config.whisper));
    
    // äº‹ä»¶è™•ç†
    asr.on('state_changed', (e) => {
      document.getElementById('status').textContent = `ç‹€æ…‹: ${e.detail.to}`;
    });
    
    asr.on('vad_speech_start', () => {
      document.getElementById('status').textContent = 'è†è½ä¸­...';
    });
    
    asr.on('transcribe_partial', (e) => {
      document.getElementById('result').textContent = e.detail.text + '...';
    });
    
    asr.on('transcribe_done', (e) => {
      document.getElementById('result').textContent = e.detail.text;
      console.log('RT Factor:', e.detail.rtFactor);
    });
    
    asr.on('backpressure', (e) => {
      console.warn('èƒŒå£“è­¦å‘Š:', e.detail);
    });
    
    asr.on('ep_fallback', (e) => {
      console.log(`åŸ·è¡Œæä¾›è€…é™ç´š: ${e.detail.from} â†’ ${e.detail.to}`);
    });
    
    asr.on('error', (e) => {
      console.error('éŒ¯èª¤:', e.detail);
      document.getElementById('status').textContent = `éŒ¯èª¤: ${e.detail.message}`;
    });
    
    // å•Ÿå‹•
    document.getElementById('start').onclick = async () => {
      await asr.start();
    };
    
    // ç’°å¢ƒå°±ç·’
    document.getElementById('start').disabled = false;
    document.getElementById('status').textContent = 'æº–å‚™å°±ç·’';
  </script>
</body>
</html>
```

## 10. æ•ˆèƒ½åŸºæº–

| æ¨¡å‹         | è£ç½®               | å¾Œç«¯   | RT Factor | å»¶é²  | å‚™è¨»   |
| ------------ | ------------------ | ------ | --------- | ----- | ------ |
| Whisper Tiny | Desktop (RTX 3060) | WebGPU | 0.05      | 50ms  | æœ€ä½³   |
| Whisper Tiny | Desktop (i7-12700) | WASM   | 0.3       | 300ms | é‡åŒ–ç‰ˆ |
| Whisper Base | Mobile (SD 888)    | WASM   | 0.8       | 800ms | å¯æ¥å— |
| Silero VAD   | All                | WASM   | 0.01      | 10ms  | æ¥µå¿«   |
| OpenWakeWord | Desktop            | WebGPU | 0.03      | 30ms  | æ¥µå¿« |

## 11. å·²çŸ¥é™åˆ¶èˆ‡è§£æ±ºæ–¹æ¡ˆ

| å•é¡Œ                     | å½±éŸ¿                       | è§£æ±ºæ–¹æ¡ˆ                              |
| ------------------------ | -------------------------- | ------------------------------------- |
| COOP/COEP é…ç½®           | ç„¡æ³•ä½¿ç”¨ SharedArrayBuffer | å¿…é ˆè¨­å®š HTTP Headersï¼ˆé meta tagsï¼‰ |
| iOS Safari MediaRecorder | éŒ„éŸ³åŠŸèƒ½å—é™               | ä½¿ç”¨ PCM fallback æˆ– polyfill         |
| Firefox WebGPU           | éœ€æ‰‹å‹•é–‹å•Ÿ                 | è‡ªå‹•é™ç´šè‡³ WebGL/WASM                 |

## 12. FAQ

### å¯¦ä½œç¶“é©—è£œå……å•ç­”

### Q: å¦‚ä½•è™•ç†ä¸åŒç€è¦½å™¨çš„ AudioContext æ¡æ¨£ç‡å·®ç•°ï¼Ÿ
**A:** å¯¦ä½œç¶“é©—é¡¯ç¤ºéœ€è¦å‹•æ…‹é‡æ¡æ¨£ï¼š
```javascript
// ä¾†è‡ªå¯¦éš›å°ˆæ¡ˆ
class AudioResampler {
  resample(inputBuffer, targetRate) {
    const inputRate = inputBuffer.sampleRate;
    if (inputRate === targetRate) return inputBuffer;
    
    const ratio = targetRate / inputRate;
    const outputLength = Math.round(inputBuffer.length * ratio);
    const output = new Float32Array(outputLength);
    
    // ç·šæ€§æ’å€¼é‡æ¡æ¨£
    for (let i = 0; i < outputLength; i++) {
      const inputIndex = i / ratio;
      const index = Math.floor(inputIndex);
      const fraction = inputIndex - index;
      
      if (index + 1 < inputBuffer.length) {
        output[i] = inputBuffer[index] * (1 - fraction) + 
                   inputBuffer[index + 1] * fraction;
      } else {
        output[i] = inputBuffer[index];
      }
    }
    
    return output;
  }
}
```

### Q: å¦‚ä½•å„ªåŒ–æ¨¡å‹è¼‰å…¥é€Ÿåº¦ï¼Ÿ
**A:** ä½¿ç”¨å¤šå±¤å¿«å–ç­–ç•¥ï¼š
1. **Prefetch**: åœ¨é é¢è¼‰å…¥æ™‚é å–æ¨¡å‹
2. **Cache API**: æŒä¹…åŒ–å„²å­˜æ¨¡å‹
3. **IndexedDB**: å¤§å‹æ¨¡å‹çš„å‚™ç”¨å„²å­˜
4. **é‡åŒ–æ¨¡å‹**: GitHub Pages ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬

### Q: å¦‚ä½•è™•ç† VAD çš„èª¤è§¸ç™¼ï¼Ÿ
**A:** å¯¦ä½œç¶“é©—å»ºè­°ä½¿ç”¨å¤šé‡é©—è­‰ï¼š
```javascript
// ä¾†è‡ª vad.js çš„å¯¦æˆ°ç­–ç•¥
class EnhancedVAD {
  constructor() {
    this.speechFrames = 0;
    this.silenceFrames = 0;
    this.minSpeechFrames = 3;  // æœ€å°‘ 3 å¹€æ‰ç¢ºèªèªéŸ³
    this.maxSilenceFrames = 12;  // 12 å¹€éœéŸ³æ‰çµæŸ
  }
  
  process(audioFrame) {
    const isSpeech = this.detector.detect(audioFrame);
    
    if (isSpeech) {
      this.speechFrames++;
      this.silenceFrames = 0;
      
      if (this.speechFrames >= this.minSpeechFrames && !this.isSpeaking) {
        this.isSpeaking = true;
        this.emit('speech_start');
      }
    } else {
      this.silenceFrames++;
      
      if (this.silenceFrames >= this.maxSilenceFrames && this.isSpeaking) {
        this.isSpeaking = false;
        this.speechFrames = 0;
        this.emit('speech_end');
      }
    }
  }
}
```

## 12. FAQ

### Q: ç‚ºä»€éº¼ SharedArrayBuffer ä¸å¯ç”¨ï¼Ÿ
**A:** éœ€è¦åœ¨ HTTP Response Headers è¨­å®š COOP/COEPï¼Œmeta tags ç„¡æ•ˆã€‚åƒè€ƒ 7.1 ç¯€å„å¹³å°è¨­å®šã€‚

### Q: å¦‚ä½•é¸æ“‡ Whisper æ¨¡å‹å¤§å°ï¼Ÿ
**A:** 
- **Tiny (39MB)**: è¡Œå‹•è£ç½®ã€å³æ™‚æ‡‰ç”¨
- **Base (74MB)**: æ¡Œé¢ã€è¼ƒé«˜ç²¾åº¦éœ€æ±‚
- **Small (244MB)**: é«˜ç²¾åº¦ã€éå³æ™‚æ‡‰ç”¨

### Q: MediaRecorder åœ¨ Safari ä¸æ”¯æ´æ€éº¼è¾¦ï¼Ÿ
**A:** ä½¿ç”¨ `getMimeType()` è‡ªå‹•åµæ¸¬ï¼Œé™ç´šè‡³ PCM ç›´æ¥éŒ„è£½æˆ–ä½¿ç”¨ polyfillã€‚

## 13. æˆæ¬Š

MIT License

## åƒè€ƒè³‡æ–™

- [ONNX Runtime Web](https://onnxruntime.ai/docs/get-started/with-javascript.html)
- [Transformers.js](https://huggingface.co/docs/transformers.js)
- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [SharedArrayBuffer & Cross-Origin Isolation](https://web.dev/cross-origin-isolation-guide/)
- [OpenWakeWord (åŸå§‹ Python ç‰ˆ)](https://github.com/dscripka/openWakeWord)